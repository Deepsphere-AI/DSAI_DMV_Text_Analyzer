{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cea8ee1-9c84-41a1-9ac0-f0b7934f1c8b",
   "metadata": {},
   "source": [
    "\n",
    "#Copyright (c) DeepSphere.AI 2021\n",
    "\n",
    "# All rights reserved\n",
    "\n",
    "# We are sharing this partial code for learning and research, and the idea behind us sharing the source code is to stimulate ideas #and thoughts for the learners to develop their ML Knowledge.\n",
    "\n",
    "# Author: # DeepSphere.AI | deepsphere.ai | dsschoolofai.com | info@deepsphere.ai\n",
    "\n",
    "# Release: Initial release\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d2091f-d1c9-4196-a3f0-02f5d343281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import re\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77c5872d-7014-44ee-8908-89cbb0ed06e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TextClassification:\n",
    "    def __init__(self,data,target_column):\n",
    "        self.data = data\n",
    "        self.target_column = target_column\n",
    "    def display_column(self):\n",
    "        print('*'*30+'COLUMN NAMES'+'*'*30+'\\n\\t\\t' ,self.data.columns)\n",
    "    def data_preprocessing(self,vAR_test_data):\n",
    "        print('*'*30+'DATA PRE-PROCESSING'+'*'*30+'\\n\\t\\t1.Remove Stop Words\\n\\t\\t2.Stemming/Lemmatization')\n",
    "        vAR_ps = PorterStemmer()\n",
    "        vAR_corpus = []\n",
    "        if vAR_test_data is None:\n",
    "            data = self.data\n",
    "        else:\n",
    "            data = vAR_test_data\n",
    "        for i in range(0, len(data)):\n",
    "            vAR_review = re.sub('[^a-zA-Z]', ' ', data['comment_text'][i])\n",
    "            vAR_review = vAR_review.lower()\n",
    "            vAR_review = vAR_review.split()\n",
    "\n",
    "            vAR_review = [vAR_ps.stem(word) for word in vAR_review if not word in stopwords.words('english')]\n",
    "            vAR_review = ' '.join(vAR_review)\n",
    "            vAR_corpus.append(vAR_review)\n",
    "        return vAR_corpus\n",
    "    def bagofwords_vectorization(self,vAR_corpus,vAR_test_data):\n",
    "        vAR_cv = CountVectorizer(max_features=5000,ngram_range=(1,3))\n",
    "        vAR_X = vAR_cv.fit_transform(vAR_corpus).toarray()\n",
    "        if vAR_test_data is None:\n",
    "            vAR_y = self.data[self.target_column]\n",
    "        else: \n",
    "            vAR_y = vAR_test_data[self.target_column]\n",
    "        return vAR_X,vAR_y\n",
    "    def tfidf_vectorization(self):\n",
    "        pass\n",
    "    def word_embedding_vectorization(self,vAR_corpus,vAR_test_data):\n",
    "        vAR_voc_size=10000\n",
    "        vAR_sent_length=8\n",
    "        vAR_onehot_repr=[one_hot(words,vAR_voc_size)for words in vAR_corpus]\n",
    "        vAR_embedded_docs=pad_sequences(vAR_onehot_repr,padding='pre',maxlen=vAR_sent_length)\n",
    "        vAR_model=Sequential()\n",
    "        vAR_model.add(Embedding(vAR_voc_size,10,input_length=vAR_sent_length))\n",
    "        vAR_model.compile('adam','mse')\n",
    "        vAR_X = vAR_model.predict(vAR_embedded_docs)\n",
    "        if vAR_test_data is None:\n",
    "            vAR_y = self.data[self.target_column]\n",
    "        else: \n",
    "            vAR_y = vAR_test_data[self.target_column]\n",
    "        return vAR_X,vAR_y\n",
    "        \n",
    "    def train_test_split(self,vAR_X,vAR_y):\n",
    "        vAR_X_train, vAR_X_test, vAR_y_train, vAR_y_test = train_test_split(vAR_X, vAR_y, test_size=0.3, random_state=0)\n",
    "        return vAR_X_train,vAR_y_train,vAR_X_test,vAR_y_test\n",
    "    def test_model(self,vAR_model,vAR_X_test):\n",
    "        vAR_prediction = vAR_model.predict(vAR_X_test)\n",
    "        return vAR_prediction\n",
    "    def accuracy_score(self,vAR_prediction,vAR_y_test):\n",
    "        score = metrics.accuracy_score(vAR_y_test, vAR_prediction)\n",
    "        return score\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a01a3051-3e29-4219-9098-feedaf6c6600",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationModels(TextClassification):\n",
    "    def __init__(self,data,target_column):\n",
    "        TextClassification.__init__(self,data,target_column)\n",
    "    def train_model_naivebayes(self,vAR_X_train,vAR_y_train):\n",
    "        vAR_model=MultinomialNB()\n",
    "        vAR_model = MultiOutputClassifier(vAR_model)\n",
    "        vAR_model.fit(vAR_X_train, vAR_y_train)\n",
    "        return vAR_model\n",
    "    def train_model_random_forest(self,vAR_X_train,vAR_y_train):\n",
    "        vAR_model=RandomForestClassifier()\n",
    "        # vAR_model = MultiOutputClassifier(vAR_model)\n",
    "        vAR_model.fit(vAR_X_train, vAR_y_train)\n",
    "        return vAR_model\n",
    "    def train_model_lstm(self,vAR_X_train,vAR_y_train,vAR_X_test,vAR_y_test):\n",
    "        # vAR_embedding_vector_features=40\n",
    "        vAR_model=Sequential()\n",
    "        # vAR_model.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\n",
    "        vAR_model.add(LSTM(100))\n",
    "        vAR_model.add(Dense(units=20, activation=\"relu\"))\n",
    "        vAR_model.add(Dense(units=20, activation=\"relu\"))\n",
    "        vAR_model.add(Dense(6,activation='relu'))\n",
    "        vAR_model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        vAR_model.fit(vAR_X_train,vAR_y_train,validation_data=(vAR_X_test,vAR_y_test),epochs=10,batch_size=64)\n",
    "        return vAR_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4416be44-0a25-43af-8f66-1d4cb4089f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************COLUMN NAMES******************************\n",
      "\t\t Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
      "       'insult', 'identity_hate'],\n",
      "      dtype='object')\n",
      "******************************DATA PRE-PROCESSING******************************\n",
      "\t\t1.Remove Stop Words\n",
      "\t\t2.Stemming/Lemmatization\n",
      "Data Preprocessing Completed\n",
      "Vectorization Completed Using Word Embedding\n",
      "Train & Test Data Splitted Successfully\n",
      "Epoch 1/10\n",
      "33/33 [==============================] - 1s 20ms/step - loss: 0.3140 - accuracy: 0.9686 - val_loss: 0.2709 - val_accuracy: 0.9944\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2911 - accuracy: 0.9952 - val_loss: 0.2690 - val_accuracy: 0.9944\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2906 - accuracy: 0.9952 - val_loss: 0.2686 - val_accuracy: 0.9944\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2903 - accuracy: 0.9952 - val_loss: 0.2685 - val_accuracy: 0.9944\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2903 - accuracy: 0.9952 - val_loss: 0.2682 - val_accuracy: 0.9944\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2898 - accuracy: 0.9952 - val_loss: 0.2684 - val_accuracy: 0.9944\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2902 - accuracy: 0.9952 - val_loss: 0.2696 - val_accuracy: 0.9944\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2909 - accuracy: 0.9952 - val_loss: 0.2690 - val_accuracy: 0.9944\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2897 - accuracy: 0.9952 - val_loss: 0.2682 - val_accuracy: 0.9944\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2901 - accuracy: 0.9952 - val_loss: 0.2686 - val_accuracy: 0.9944\n",
      "LSTM Model Trained successfully\n",
      "LSTM Model Tested successfully\n",
      "Xtest length -  109\n",
      "******************************DATA PRE-PROCESSING******************************\n",
      "\t\t1.Remove Stop Words\n",
      "\t\t2.Stemming/Lemmatization\n",
      "Data Preprocessing Completed\n",
      "Vectorization Completed Using Word Embedding\n",
      "Naive Bayes Model Tested successfully\n",
      "ypred length -  109\n",
      "                   id                                       comment_text  \\\n",
      "89   b794843f3d6044f3  Thanks Ched. I consider that high praise from ...   \n",
      "90   b7949b0106cfee4f  Please see #Proposal_to_radically_reduce_the_n...   \n",
      "91   b79531d31c7efc92  \" \\n \\n  == hey bud == \\n \\n  {| style=\"\"backg...   \n",
      "92   b795b454d7b117e5  \" \\n  :LOL, you are dealing with Australians h...   \n",
      "93   b795b69fcfcfd3a9        :Please see my comments on the DRV listing.   \n",
      "94   b796e3239ac15c60                                            #ERROR!   \n",
      "95   b79895a40d19d3de  Dear Barneca \\n  You are an idiot. How dare yo...   \n",
      "96   b799019c26ded5f5  Niamh Byrne is a single parent , after getting...   \n",
      "97   b7990f7d2ba333df  I have never looked at the page on Polar Bears...   \n",
      "98   b799b395bec7c7c1           me what to do arrogant genius! PLEASE!!!   \n",
      "99   b79b09e3a021a8e5  \":At a quick glance, the Smallville Wikia epis...   \n",
      "100              xyz1                                             Bloody   \n",
      "101              xyz2                                               Shit   \n",
      "102              xyz5                                           Talibans   \n",
      "103              xyz6                                          Terrorist   \n",
      "104              xyz7                                             Stupid   \n",
      "105              xyz8                                              Moist   \n",
      "106              xyz9                                             EETASS   \n",
      "107             xyz10                                           KYLBIDEN   \n",
      "108             xyz11                                            OSX4EVA   \n",
      "\n",
      "        toxic  severe_toxic  obscene  threat    insult  identity_hate  \n",
      "89   0.105078      0.019020      0.0     0.0  0.062794       0.000000  \n",
      "90   0.118707      0.024701      0.0     0.0  0.069115       0.000000  \n",
      "91   0.110741      0.022456      0.0     0.0  0.061270       0.000000  \n",
      "92   0.125556      0.031114      0.0     0.0  0.068092       0.000000  \n",
      "93   0.099062      0.015160      0.0     0.0  0.053037       0.000000  \n",
      "94   0.056819      0.000000      0.0     0.0  0.025602       0.000000  \n",
      "95   0.103083      0.016283      0.0     0.0  0.058987       0.000000  \n",
      "96   0.103372      0.018141      0.0     0.0  0.059232       0.000000  \n",
      "97   0.112550      0.022583      0.0     0.0  0.062481       0.000000  \n",
      "98   0.061729      0.000000      0.0     0.0  0.028368       0.000000  \n",
      "99   0.108759      0.018592      0.0     0.0  0.061090       0.000000  \n",
      "100  0.059762      0.000000      0.0     0.0  0.025823       0.000000  \n",
      "101  0.057180      0.000000      0.0     0.0  0.024762       0.000092  \n",
      "102  0.059150      0.000000      0.0     0.0  0.026223       0.000000  \n",
      "103  0.058348      0.000000      0.0     0.0  0.025140       0.000000  \n",
      "104  0.057724      0.000000      0.0     0.0  0.024948       0.000135  \n",
      "105  0.058016      0.000000      0.0     0.0  0.025531       0.000000  \n",
      "106  0.059579      0.000000      0.0     0.0  0.026210       0.000000  \n",
      "107  0.060262      0.000000      0.0     0.0  0.025710       0.000000  \n",
      "108  0.059097      0.000000      0.0     0.0  0.028231       0.000000  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    vAR_data = pd.read_csv('/home/jupyter/DSAI_DMV_Text_Analyzer/DSAI_Dataset/train.csv').head(3000)\n",
    "    vAR_target_columns = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "    vAR_model_obj = ClassificationModels(vAR_data,vAR_target_columns)\n",
    "    vAR_model_obj.display_column()\n",
    "    vAR_test_data = None\n",
    "    vAR_corpus = vAR_model_obj.data_preprocessing(vAR_test_data)\n",
    "    print('Data Preprocessing Completed')\n",
    "    \n",
    "############## *****Execute Below Code For NaiveBayes Classification***** ##############\n",
    "\n",
    "#     vAR_X,vAR_y = vAR_model_obj.bagofwords_vectorization(vAR_corpus,vAR_test_data)\n",
    "#     print('Vectorization Completed Using Bag of Words')\n",
    "#     vAR_X_train,vAR_y_train,vAR_X_test,vAR_y_test = vAR_model_obj.train_test_split(vAR_X,vAR_y)\n",
    "#     print('Train & Test Data Splitted Successfully')\n",
    "\n",
    "#     vAR_model = vAR_model_obj.train_model_naivebayes(vAR_X_train,vAR_y_train)\n",
    "#     print('Naive Bayes Model Trained successfully')\n",
    "#     vAR_prediction = vAR_model_obj.test_model(vAR_model,vAR_X_test)\n",
    "#     print('Naive Bayes Model Tested successfully')\n",
    "#     accuracy = vAR_model_obj.accuracy_score(vAR_prediction,vAR_y_test)\n",
    "#     print('Naive Bayes Model Accuracy - ',accuracy)\n",
    "\n",
    "############## ******************************************************** ###############\n",
    "\n",
    "############## *****Execute Below Code For Random Forest Classification***** ##############\n",
    "    \n",
    "    # vAR_X,vAR_y = vAR_model_obj.bagofwords_vectorization(vAR_corpus,vAR_test_data)\n",
    "    # print('Vectorization Completed Using Bag of Words')\n",
    "    # vAR_X_train,vAR_y_train,vAR_X_test,vAR_y_test = vAR_model_obj.train_test_split(vAR_X,vAR_y)\n",
    "    # print('Train & Test Data Splitted Successfully')\n",
    "    # vAR_model = vAR_model_obj.train_model_random_forest(vAR_X_train,vAR_y_train)\n",
    "    # print('Random Forest Model Trained successfully')\n",
    "    # vAR_prediction = vAR_model_obj.test_model(vAR_model,vAR_X_test)\n",
    "    # print('Random Forest Model Tested successfully')\n",
    "    # accuracy = vAR_model_obj.accuracy_score(vAR_prediction,vAR_y_test)\n",
    "    # print('Random Forest Model Accuracy - ',accuracy)\n",
    "\n",
    "############## ******************************************************** ###############\n",
    "    \n",
    "############## *****Execute Below Code For LSTM RNN Deep Learning Model***** ############## \n",
    "\n",
    "    vAR_X,vAR_y = vAR_model_obj.word_embedding_vectorization(vAR_corpus,vAR_test_data)\n",
    "    print('Vectorization Completed Using Word Embedding')\n",
    "    vAR_X_train,vAR_y_train,vAR_X_test,vAR_y_test = vAR_model_obj.train_test_split(vAR_X,vAR_y)\n",
    "    print('Train & Test Data Splitted Successfully')\n",
    "    \n",
    "    vAR_model = vAR_model_obj.train_model_lstm(vAR_X_train,vAR_y_train,vAR_X_test,vAR_y_test)\n",
    "    print('LSTM Model Trained successfully')\n",
    "    vAR_prediction = vAR_model_obj.test_model(vAR_model,vAR_X_test)\n",
    "    print('LSTM Model Tested successfully')\n",
    "    \n",
    "############## ******************************************************** ###############\n",
    "\n",
    "\n",
    "############## *****Execute Below Code When You want to test the model with custom text data***** ##############\n",
    "    \n",
    "    vAR_test_data = pd.read_csv('/home/jupyter/DSAI_DMV_Text_Analyzer/DSAI_Dataset/test-compress-all-labels.csv')\n",
    "    vAR_X_test_data = vAR_test_data.drop(['toxic','severe_toxic','obscene','threat','insult','identity_hate'],axis=1)\n",
    "    print('Xtest length - ',len(vAR_test_data))\n",
    "    vAR_corpus = vAR_model_obj.data_preprocessing(vAR_test_data)\n",
    "    print('Data Preprocessing Completed')\n",
    "    vAR_X,vAR_y = vAR_model_obj.word_embedding_vectorization(vAR_corpus,vAR_test_data)\n",
    "    print('Vectorization Completed Using Word Embedding')\n",
    "    vAR_prediction = vAR_model_obj.test_model(vAR_model,vAR_X)\n",
    "    print('Naive Bayes Model Tested successfully')\n",
    "    print('ypred length - ',len(vAR_prediction))\n",
    "    vAR_X_test_data['toxic'] = vAR_prediction[:,0]\n",
    "    vAR_X_test_data['severe_toxic'] = vAR_prediction[:,1]\n",
    "    vAR_X_test_data['obscene'] = vAR_prediction[:,2]\n",
    "    vAR_X_test_data['threat'] = vAR_prediction[:,3]\n",
    "    vAR_X_test_data['insult'] = vAR_prediction[:,4]\n",
    "    vAR_X_test_data['identity_hate'] = vAR_prediction[:,5]\n",
    "    vAR_X_test_data.to_csv('/home/jupyter/DSAI_DMV_Text_Analyzer/DSAI_Model_Outcome/DSAI_Model_Outcome.csv')\n",
    "    print(vAR_X_test_data.tail(20))\n",
    "    \n",
    "############## ******************************************************** ###############\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408f0b48-df67-4f2a-a57f-aa5de1d64c85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
